{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27ba1660-aee0-43d4-9b88-3fe5efdca5c1",
   "metadata": {},
   "source": [
    "# Machine learning and text data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec008a87-2e7e-4dab-8762-9d2f3e33ceff",
   "metadata": {},
   "source": [
    "## Importing resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb25fdb2-742a-40b5-8a95-ffcbdcf2575b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk # the module\n",
    "nltk.download('gutenberg') # a selection of sample texts\n",
    "nltk.download('genesis')\n",
    "nltk.download('inaugural')\n",
    "nltk.download('nps_chat')\n",
    "nltk.download('webtext')\n",
    "nltk.download('treebank')\n",
    "nltk.download('udhr')\n",
    "nltk.download('wordnet') # utilities\n",
    "nltk.download('punkt')\n",
    "nltk.download('tagsets')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7343471e-ab27-4fe4-bb61-ee0a8c24c755",
   "metadata": {},
   "source": [
    "## Exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28d2be7-4cf6-4335-9e23-f6cc63fcbcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at a text's title\n",
    "text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ed8abd-1da4-46f0-af2c-a5a7f58afbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the first sentence of the text\n",
    "# sent1 is the first sentence of text1 etc\n",
    "sent1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76abe36c-16ab-4942-b6e0-053bbebf8874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see how long the text is\n",
    "len(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9999a2f-39e3-415b-abdf-866f4fd9a3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# or how long a sentence is\n",
    "len(sent1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8cdd56-f3e9-4413-8c5e-c54737c1d8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many unique words in a text?\n",
    "len(set(text1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6883a497-0ed4-4747-be77-820e2bb67a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what are the first 10 unique words?\n",
    "list(set(text1))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e27c27-784d-4fa7-a607-2d86de82f78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what are the first 10 unique words in alphabetical order?\n",
    "list(sorted(set(text1)))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac27c0b-a871-476a-8893-3d56d7415219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequency of words in a text\n",
    "dist = FreqDist(text1)\n",
    "print('There are ', len(dist), 'words in the distribution.')\n",
    "vocab1 = dist.keys()\n",
    "print('The first 10 words in the distribution are:\\n', list(vocab1)[:10])\n",
    "print('The word \"whale\" appears ', dist['whale'], 'times.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb87b3c9-e114-4f19-8607-2a66367493a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist['he']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18769b63-c651-49f4-ae20-21d694ef981a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering for certain types of words\n",
    "# e.g. more than 5 letters, appears more than 100 times\n",
    "freqwords = [w for w in vocab1 if len(w) > 5 and dist[w] > 100]\n",
    "freqwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ee1b96-5cd7-4d2c-acb7-2361ccd2cee3",
   "metadata": {},
   "source": [
    "## Working with words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894b8e0b-d1b2-4973-b623-a7a082e438d3",
   "metadata": {},
   "source": [
    "### Normalization, stemming and lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cdcfd3-4f75-4893-bece-4d2bc7f67bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize\n",
    "input1 = \"List listed lists listing listings\"\n",
    "words1 = input1.lower().split(' ')\n",
    "words1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74520743-dc40-4208-b2cd-09ba983056f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the stem for each word\n",
    "porter = nltk.PorterStemmer()\n",
    "[porter.stem(t) for t in words1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e264182-5d64-4c85-8053-88b49c4c48eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatize each word\n",
    "WNlemma = nltk.WordNetLemmatizer()\n",
    "[WNlemma.lemmatize(t) for t in words1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d4372f-57cd-426a-a7b4-a217ca77b924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try with a different set of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994caa84-05e0-464f-af68-7c6cb84cc52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "udhr = nltk.corpus.udhr.words('English-Latin1')\n",
    "udhr[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df40fe4-7bdb-441c-8e8a-4bba895fc80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "port = [porter.stem(t) for t in udhr[:20]]\n",
    "WNlemma = nltk.WordNetLemmatizer()\n",
    "lemma = [WNlemma.lemmatize(t) for t in udhr[:20]]\n",
    "print(port, '\\n', lemma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e416b8a6-96c8-43c3-93bf-2c3cb47af376",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a79cdfa-1b31-4f32-86ff-98a5e158759f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple string split \n",
    "text11 = \"Children shouldn't drink a sugary drink before bed.\" # a sample sentence\n",
    "text11.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2785242a-fcb1-4a9b-a2c6-2c7cface61ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using nltk inbuilt 'tokenize' function\n",
    "nltk.word_tokenize(text11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c5265d-4ab7-4816-8581-6ab222d1f0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting sentences using another inbuilt function\n",
    "text12 = \"This is the first sentence. A gallon of milk in the U.S. costs $2.99. Is this the third sentence? Yes, it is!\"\n",
    "sentences = nltk.sent_tokenize(text12)\n",
    "print('There are', len(sentences), 'sentences.')\n",
    "print('They are:\\n', sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78924024-3ea3-4173-9dad-5ade9118ec9f",
   "metadata": {},
   "source": [
    "### Recognising and tagging parts of speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12c3780-1f4d-4b8f-9cd4-cafc82fe8944",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.help.upenn_tagset('N') # what does this do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3154ee-0360-4408-b1a7-0ed046d196c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text14 = nltk.word_tokenize(\"Lucy loves Power BI except when she doesn't\")\n",
    "nltk.pos_tag(text14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37afbfc4-45b4-4b00-9e6b-53c0b6d2437d",
   "metadata": {},
   "source": [
    "### POS tagging and parsing ambiguity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01782ac-3ffe-48ec-80c2-9243e35d8386",
   "metadata": {},
   "outputs": [],
   "source": [
    "text18 = nltk.word_tokenize(\"The old man the boat\")\n",
    "nltk.pos_tag(text18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f62831a-8d85-4619-9f6c-cfe8ebd7238a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text19 = nltk.word_tokenize(\"Colorless green ideas sleep furiously\")\n",
    "nltk.pos_tag(text19)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3966b45c-20ee-489b-a279-75850071d56c",
   "metadata": {},
   "source": [
    "## Sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3f0ffc-7e4a-43c3-8366-acc3117a0cb3",
   "metadata": {},
   "source": [
    "### Fetch the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d324b6f5-fdc0-466f-b860-6cc35e4ffb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read in the data\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/jargonautical/bsuBootcamp/refs/heads/main/Amazon_Unlocked_Mobile.csv')\n",
    "\n",
    "# Sample the data to speed up computation (optional)\n",
    "df = df.sample(frac=0.1, random_state=10)\n",
    "\n",
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bda9ba-f6ca-42e1-8382-6de76cf93c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Remove any 'neutral' ratings equal to 3 (why do we do this?)\n",
    "df = df[df['Rating'] != 3]\n",
    "\n",
    "# Encode 4s and 5s as 1 (rated positively)\n",
    "# Encode 1s and 2s as 0 (rated poorly)\n",
    "df['Positively Rated'] = np.where(df['Rating'] > 3, 1, 0)\n",
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4f7661-7724-4cba-9d6c-c02193ceaa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the data\n",
    "# Are there more positive or more negative ratings in our sample?\n",
    "df['Positively Rated'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cd2383-3cab-4238-bccf-74e8f3515ae6",
   "metadata": {},
   "source": [
    "### Train / Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0560ff-a2b6-4e13-9f65-48b51456d76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Reviews'], \n",
    "                                                    df['Positively Rated'], \n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a951dfea-9a2c-4fb6-8318-7726ebf8d929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick check to see what it looks like\n",
    "print('X_train first entry:\\n\\n', X_train.iloc[0])\n",
    "print('\\n\\nX_train shape: ', X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8cdef7-79da-49da-8dea-619ca2653c2c",
   "metadata": {},
   "source": [
    "### Reshape the data as the model requires it - VECTORIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b93cac1-6445-4144-a726-8f243b570be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# Fit the CountVectorizer to the training data\n",
    "vect = CountVectorizer().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ca7ece-4302-47b4-bfeb-e688f86a68b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect.get_feature_names_out()[::2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb02b86-37e5-4c87-b14b-4dcf5728b8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vect.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e19a17b-4625-4737-a50c-95a638d98550",
   "metadata": {},
   "source": [
    "### Transform the training data and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19268731-2b62-4c8f-acc0-65a4f1aa5458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the documents in the training data to a document-term matrix\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "X_train_vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9146f359-3569-42d7-accc-847e17e6bdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Train the model (why have we chosen this one?)\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebabbc3-cc4a-4d2f-a4c0-15a07e021e69",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19285d35-ed7e-4185-a3b9-667f0c3e97c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Predict the transformed test documents\n",
    "predictions = model.predict(vect.transform(X_test))\n",
    "\n",
    "print('AUC: ', roc_auc_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02decce-2202-4a45-9cf5-eb312583961e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the feature names as numpy array\n",
    "feature_names = np.array(vect.get_feature_names_out())\n",
    "\n",
    "# Sort the coefficients from the model\n",
    "sorted_coef_index = model.coef_[0].argsort()\n",
    "\n",
    "# Find the 10 smallest and 10 largest coefficients\n",
    "# The 10 largest coefficients are being indexed using [:-11:-1] \n",
    "# so the list returned is in order of largest to smallest\n",
    "print('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\n",
    "print('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2b5cff-78a5-4149-9806-2799e06216ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUT ... we have a problem!\n",
    "# These 2 reviews are treated the same by our current model\n",
    "print(model.predict(vect.transform(['not an issue, phone is working',\n",
    "                                    'an issue, phone is not working'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a097b71-0740-4209-a2ff-130dcb998939",
   "metadata": {},
   "source": [
    "### Using n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53131830-4c46-4fef-8d16-85e78066aaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the CountVectorizer to the training data specifiying a minimum \n",
    "# document frequency of 5 and extracting 1-grams and 2-grams\n",
    "vect = CountVectorizer(min_df=5, ngram_range=(3,5)).fit(X_train)\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_vectorized, y_train)\n",
    "predictions = model.predict(vect.transform(X_test))\n",
    "print('AUC: ', roc_auc_score(y_test, predictions))\n",
    "feature_names = np.array(vect.get_feature_names_out())\n",
    "sorted_coef_index = model.coef_[0].argsort()\n",
    "print('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\n",
    "print('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb393643-238c-410e-b52a-dd28f30ea3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These reviews are now correctly identified\n",
    "print(model.predict(vect.transform(['not an issue, phone is working',\n",
    "                                    'an issue, phone is not working'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9293a00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_roc_curve(true_y, y_prob):\n",
    "    \"\"\"\n",
    "    plots the roc curve based of the probabilities\n",
    "    \"\"\"\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(true_y, y_prob)\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c406092f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(y_test, predictions)\n",
    "print(f'model 1 AUC score: {roc_auc_score(y_test, predictions)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345af7dd-cf22-4d11-800e-7f61ac44dab4",
   "metadata": {},
   "source": [
    "## Topic modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1568d583-9afa-47fb-9f79-6b76ef270829",
   "metadata": {},
   "source": [
    "### Course and teaching reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7460381e-606d-4d49-a14b-d0467799a6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/jargonautical/bsuBootcamp/refs/heads/main/reviews.csv')\n",
    "df = df.sample(frac=0.1, random_state=10)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37731f0-e37e-458b-9fe5-d898713f0d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sia=SentimentIntensityAnalyzer()\n",
    "df['polarity scores'] = df['Review'].apply(lambda x: sia.polarity_scores(x)['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f40ed8-a5a3-4560-a297-9a4135ab12e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbc145f-6cce-4c9a-bd97-9c383e3e7441",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "stopwords = set(STOPWORDS)\n",
    "\n",
    "def show_wordcloud(data, title = None):\n",
    "    wordcloud = WordCloud(\n",
    "        background_color='white',\n",
    "        stopwords=stopwords,\n",
    "        max_words=200,\n",
    "        max_font_size=40, \n",
    "        scale=3,\n",
    "        random_state=1 # chosen at random by flipping a coin; it was heads\n",
    "    ).generate(str(data))\n",
    "\n",
    "    fig = plt.figure(1, figsize=(8, 8))\n",
    "    plt.axis('off')\n",
    "    if title: \n",
    "        fig.suptitle(title, fontsize=20)\n",
    "        fig.subplots_adjust(top=2.3)\n",
    "\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.show()\n",
    "\n",
    "show_wordcloud(df['Review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0dced3-7ebb-4713-98dc-ada030bc7dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as ss # for making sparse matrices\n",
    "from corextopic import corextopic as ct # a topic modelling methodology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a47b829-741c-411e-ac02-f64c5fef6992",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english', lowercase=True, binary=True)\n",
    "corex_docs = df['Review'].tolist()\n",
    "doc_word = vectorizer.fit_transform(corex_docs)\n",
    "doc_word = ss.csr_matrix(doc_word)\n",
    "words = list(np.asarray(vectorizer.get_feature_names_out()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714eea4b-ad77-4373-8f09-405ca4c8a827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extending stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = list(stopwords.words('english'))\n",
    "stop_words.extend(['andrew', 'ng', 'chuck', 'israel', 'really'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce4cc42-150f-426c-b188-49b8d2b4382f",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_num_topics = 20 # num topics CorEx will identify\n",
    "topic_model = ct.Corex(n_hidden=target_num_topics, words=words, max_iter=1000, verbose=False, seed=2020)\n",
    "topic_model.fit(doc_word, words=words);\n",
    "topics = topic_model.get_topics()\n",
    "for c in [col for col in df.columns if col.startswith('topic_')]:\n",
    "    del df[c]\n",
    "for topic_num in range(0, len(topics)):\n",
    "    df['topic_' + str(topic_num)] = topic_model.log_p_y_given_x[:,topic_num]\n",
    "corex_cols = [col for col in df if col.startswith('topic_')]\n",
    "df['best_topic'] = df[corex_cols].idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3008e7fb-3960-48d6-8127-96ca057822fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n,topic in enumerate(topics):\n",
    "    topic_words, foo, bar = zip(*topic)\n",
    "    outText = 'topic_' + str(n) + ',' + ','.join(topic_words) + '\\n'\n",
    "    print(outText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104159a8-abf4-424e-99de-ce949fe7b8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b154f3a-fb78-468f-8547-1c14b42898ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Choosing our own topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b348cd6-6176-4c10-929c-e7745a66510d",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_words = ['confidence', 'practical', 'interesting', 'video','assignment']\n",
    "topic_model.fit(doc_word, words=words, anchors=anchor_words, anchor_strength=6);\n",
    "topics = topic_model.get_topics()\n",
    "topic_list = []\n",
    "\n",
    "for n,topic in enumerate(topics):\n",
    "    topic_words, foo, bar = zip(*topic)\n",
    "    outText = 'topic_' + str(n) + ',' + ','.join(topic_words) + '\\n'\n",
    "    print(outText)\n",
    "    #with open('topicsList.txt', 'a') as f:\n",
    "    #    # write a row to the  file\n",
    "    #    f.write(outText)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c3f545-eb8c-4b8f-9c7c-8b6448a766a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.bar(range(topic_model.tcs.shape[0]), topic_model.tcs, color='#4e79a7', width=0.5)\n",
    "plt.xlabel('Topic', fontsize=16)\n",
    "plt.ylabel('Total Correlation (nats)', fontsize=16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4481e02-7ebe-423c-b65a-9bf860b5cecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extending stopwords\n",
    "stop_words.extend(['words', 'I', 'want', 'to', 'exclude'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d18f29e-32d9-4f92-89f9-71bc395fac33",
   "metadata": {},
   "source": [
    "### Visualising your analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6a12db-c58f-424d-a576-f67d05bc51c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the topic IDs and descriptions to text file\n",
    "for n,topic in enumerate(topics):\n",
    "    topic_words, foo, bar = zip(*topic)\n",
    "    outText = 'topic_' + str(n) + ',' + ','.join(topic_words) + '\\n'\n",
    "    with open('topicsList.txt', 'a') as f:\n",
    "        # write a row to the  file\n",
    "        f.write(outText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236f7b58-7964-4887-9fb9-8810d2e26f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the dataframe to CSV \n",
    "# (if you want to visualise in another platform)\n",
    "df.to_csv('data_out.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcb8cf9",
   "metadata": {},
   "source": [
    "# Practical  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0157b7",
   "metadata": {},
   "source": [
    "### Using machine learning to analyse text in the Movies dataset\n",
    "We haven't found any strong patterns or clusters in the numeric columns.\n",
    "Perhaps we should be guiding our client towards the *style* of movie they ought to make?  \n",
    "#### Q 1: Define the problem.\n",
    "How do we phrase the question as one that a machine learning model can solve?  \n",
    "#### Q 2: Feature selection\n",
    "Which attributes in the data can we use?\n",
    "#### Q 3: Model selection\n",
    "Which model would be appropriate or relevant here?  \n",
    "Is there more than one answer to this question?\n",
    "#### Q 4: Data preparation\n",
    "Once we've chosen a model, what does the data need to look like?  \n",
    "#### NOT FORGETTING ...\n",
    "If you had an answer, what would it look like?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
